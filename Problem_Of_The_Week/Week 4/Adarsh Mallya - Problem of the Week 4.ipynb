{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5edfd277-8f73-4ee7-a000-6a10d3c2541f",
   "metadata": {},
   "source": [
    "# Problem of the Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f44593-daf7-4b70-8b40-2b4c12884893",
   "metadata": {},
   "source": [
    "Name: Adarsh Mallya\n",
    "\n",
    "Student ID: 017086225\n",
    "\n",
    "Date: 09/14/2025\n",
    "\n",
    "**Motivation**\n",
    "\n",
    "This week's Problem of the Week is provides a reflection on the new classification models we looked at this week. Here, we will compare and contrast the $k$-nearest neighbor (KNN) and decision tree (DT) models from Lecture 4-2.\n",
    "\n",
    "**Completing this assignment**\n",
    "\n",
    "To complete this assignment, fill in the markdown cells with your responses. When complete, upload this notebook as a Jupyter notebook AND a PDF to Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59ad35-1320-4c31-87cb-ec7202704606",
   "metadata": {},
   "source": [
    "## Problem 4.1: Model Description\n",
    "\n",
    "To begin, let's remind ourselves how each model was designed. Write one or two sentence for each model that describes the principle underlying the model construction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4879b47e-277d-4201-8cd5-53571895ad9a",
   "metadata": {},
   "source": [
    "KNN Model:\n",
    "The KNN model was designed by computing the Euclidean distance of every point to the chosen point that is the subject of classification, then focusing on the k nearest ones. The classification of the chosen point was made by choosing the most common classification among the k nearest neighbors.\n",
    "\n",
    "DT Model:\n",
    "The DT model works by evaluating a condition to determine whether a point belongs to a certain classification or not. By continuing down this binary selection process, the classification can be narrowed down to one label.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907fdb91-3bfe-4f2a-aab7-9cb012dabe0d",
   "metadata": {},
   "source": [
    "## Problem 4.2: Model Hyperparameters\n",
    "\n",
    "Both the KNN and DT models have hyperparameters that define their structure. These parameters are chosen by the user when constructing the model. List one of the key hyperparameters used for each of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6eef1b-1f45-4b4f-9d4f-90c47a48c4ca",
   "metadata": {},
   "source": [
    "KNN Model:\n",
    "One key hyperparameter of the KNN model is the value of k, or the number of neighbors that are used in classifying the chosen point. \n",
    "\n",
    "DT Model:\n",
    "One key hyperparameter of the DT model is the maximum depth of the tree, which determines how many evaluations are made about the point as it works further and further into the classification process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94423606-326c-4766-8069-fa7c886fb1c7",
   "metadata": {},
   "source": [
    "## Problem 4.3: Model Similarities and Differences\n",
    "\n",
    "Both the KNN and DT models work similarly to classify regions of a feature space. What is one way that KNNs and DTs are similar? What is one way in which they are different?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c92d46-472a-4772-9e7d-7bea4a85adea",
   "metadata": {},
   "source": [
    "Similarity: Both KNN and DT models are constructed according to rules that are guided by the available data and their classifications.\n",
    "\n",
    "\n",
    "Difference: KNN classifies based on the proximity of the point to other points, while DT classifies based on similarity of the qualities of the point to other points.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b79f8e-8ee8-4b48-a1dd-865cbf5e9e8a",
   "metadata": {},
   "source": [
    "## Problem 4.4: Model Benefits\n",
    "\n",
    "What is one benefit of using each of the models seen this week compared to other classification models we have seen? Write one sentence for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55276641-3857-4bd7-9d22-5cdf692db3e5",
   "metadata": {},
   "source": [
    "KNN Model: KNN models are flexible, as they can adapt according to a change in the number of neighbors that are chosen to be focused on.\n",
    "\n",
    "\n",
    "DT Model: DT models are very intuitive, as they utilize binary conditions to determine if a point belongs or doesn't belong to a classification.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c45cbb-b1b7-4cf9-8823-fe2f255f434c",
   "metadata": {},
   "source": [
    "## Problem 4.5: Model Drawbacks\n",
    "\n",
    "What is one drawback of using the models we have seen in this week compared to other classification models we have seen? Write on sentence for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4140778-f170-4d5e-bcdf-659869081473",
   "metadata": {},
   "source": [
    "KNN Model: The KNN model can be susceptible to outliers far more easily than many other classification models, due to its main classification process being based on what are the nearest neighbors.\n",
    "\n",
    "\n",
    "DT Model: Because of the tree structure, DT models can be more computationally expensive than some other models, as in the worst case it will require as many computations as there are possible labels.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs171",
   "language": "python",
   "name": "cs171"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
